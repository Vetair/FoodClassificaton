# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_NoZ4oIwQpTL-wLikEBwEdiTwW6E6SBm

# Download Food Classification dataset from kaggle
"""

!pip install kaggle

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d harishkumardatalab/food-image-classification-dataset

!unzip food-image-classification-dataset.zip

!unzip Food Backup.zip

"""

*   Upload to google drive

"""

!cp -r /content/Food\ Classification\ dataset /content/drive/MyDrive/Colab\ Notebooks/Projects/datasets

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

image_path = '/content/Food Classification dataset/sushi/100332.jpg'

img = mpimg.imread(image_path)

plt.imshow(img)
plt.axis('off')
plt.show()

"""# Data visualization"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm

import matplotlib.pyplot as plt
# %matplotlib inline

# Specify the dataset path
dataset_path = '/content/Food Classification dataset'
os.chdir(dataset_path)
os.listdir()

import pandas as pd

# Create an empty list to store individual DataFrames
dfs = []

for food in tqdm(os.listdir()): # Iterate through each category
    os.chdir(food)
    category_data = []  # Create a list to store data for each category
    for file in os.listdir(): # Iterate through each image
        try:
            img = cv2.imread(file)
            category_data.append({'Category': food, 'Filename': file, 'Image Width': img.shape[1], 'Image Height': img.shape[0]})
        except:
            print(os.path.join(food, file), 'Read Error')
    category_df = pd.DataFrame(category_data)  # Create a DataFrame for the current category
    dfs.append(category_df)  # Append the DataFrame to the list
    os.chdir('../')

# Concatenate all DataFrames in the list into a single DataFrame
df = pd.concat(dfs, ignore_index=True)

df

from scipy.stats import gaussian_kde
from matplotlib.colors import LogNorm

# Extracting image width and height
width = df['Image Width']
height = df['Image Height']

# Calculate density using Gaussian KDE
kde = gaussian_kde([width, height])
density = kde([width, height])

# Sort the points by density
sorted_indices = density.argsort()
width, height, density = width[sorted_indices], height[sorted_indices], density[sorted_indices]

plt.figure(figsize=(10,10))

# Create scatter plot
plt.scatter(width, height, c=density, s=5, cmap='Spectral_r')

plt.tick_params(labelsize=15)

max_dimension = max(max(df['Image Width']), max(df['Image Height']))
plt.xlim(0, max_dimension)
plt.ylim(0, max_dimension)

plt.ylabel('Height', fontsize=25)
plt.xlabel('Width', fontsize=25)

plt.savefig('Image_Size_Distribution.pdf', dpi=120, bbox_inches='tight')

plt.show()

"""# Split the dataset into a training set and a test set"""

# Commented out IPython magic to ensure Python compatibility.
import os
import shutil
import random
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from mpl_toolkits.axes_grid1 import ImageGrid
# %matplotlib inline

import numpy as np
import math
import os

import cv2

from tqdm import tqdm

"""* Get all class names"""

# Specify dataset path
dataset_path = '/content/Food Classification dataset'

dataset_name = dataset_path.split('_')[0]
print('Dataset:', dataset_name)

classes = os.listdir(dataset_path)
len(classes)
classes

"""* Create train and test folders"""

os.mkdir(os.path.join(dataset_path, 'train'))
os.mkdir(os.path.join(dataset_path, 'test'))

# Create subfolders for each class in train and test folders
for food in classes:
    os.mkdir(os.path.join(dataset_path, 'train', food))
    os.mkdir(os.path.join(dataset_path, 'test', food))

"""* Split training sets, test sets, move files"""

test_frac = 0.2  # Test set fraction
random.seed(123)  # Random seed for reproducibility

df_list = []  # Create an empty list to store individual DataFrames
print('{:^18} {:^18} {:^18}'.format('Class', 'Trainset Data Count', 'Testset Data Count'))

for food in classes:  # Iterate through each class

    # Reads all image file names for this category
    old_dir = os.path.join(dataset_path, food)
    images_filename = os.listdir(old_dir)
    random.shuffle(images_filename)  # Shuffle images randomly

    # Split datasets
    testset_numer = int(len(images_filename) * test_frac)  # Number of images in test set
    testset_images = images_filename[:testset_numer]  # Images to move to the test directory
    trainset_images = images_filename[testset_numer:]  # Images to move to the train directory

    # Move images to the test directory
    for image in testset_images:
        old_img_path = os.path.join(dataset_path, food, image)
        new_test_path = os.path.join(dataset_path, 'test', food, image)
        shutil.move(old_img_path, new_test_path)

    # Move images to the train directory
    for image in trainset_images:
        old_img_path = os.path.join(dataset_path, food, image)
        new_train_path = os.path.join(dataset_path, 'train', food, image)
        shutil.move(old_img_path, new_train_path)

    #Delete old folders
    assert len(os.listdir(old_dir)) == 0  # Ensure all images in the old folder have been moved
    shutil.rmtree(old_dir)  # Delete the folder

    # print the number of data for each category
    print('{:^18} {:^18} {:^18}'.format(food, len(trainset_images), len(testset_images)))

    df_list.append(pd.DataFrame({'Class': [food], 'Trainset Data Count': [len(trainset_images)], 'Testset Data Count': [len(testset_images)]}))

df = pd.concat(df_list, ignore_index=True)  # Concatenate all DataFrames in the list into a single DataFrame

# Rename the split dataset
shutil.move(dataset_path, dataset_name+'_split')

# Statistical table for dataset categories, exported as csv file
df['Total'] = df['Trainset Data Count'] + df['Testset Data Count']
df.to_csv('Data_Count.csv', index=False)

df

"""

*   Visualize images in folders


"""

folder_path = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split/train/cheesecake'

# Number of visualized images
N = 25

# n rows and n columns
n = math.floor(np.sqrt(N))
n

images = []
for each_img in os.listdir(folder_path)[:N]:
    img_path = os.path.join(folder_path, each_img)
    img_bgr = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    images.append(img_rgb)

len(images)

fig = plt.figure(figsize=(10, 10))
grid = ImageGrid(fig, 111,
                 nrows_ncols=(n, n),
                 axes_pad=0.02,
                 share_all=True
                 )

for ax, im in zip(grid, images):
    ax.imshow(im)
    ax.axis('off')

plt.tight_layout()
plt.show()

"""* Count the number of images in each category"""

df = pd.read_csv('/content/Data_Count.csv')

df.shape

# Specify visualized features
feature = 'Total'

df = df.sort_values(by=feature, ascending=False)

df.head()

x = df['Class']
y = df[feature]

plt.figure(figsize=(10, 5))
plt.bar(x, y, facecolor='#ff7f0e', edgecolor='black', linewidth=1.5, alpha=0.7, width=0.5)
plt.xlabel('Categories')
plt.ylabel('Numbers')
plt.grid(True, linestyle='--', alpha=0.6, axis='y')
plt.show()

x = df['Class']
y1 = df['Testset Data Count']
y2 = df['Trainset Data Count']

plt.figure(figsize=(10, 5))

plt.bar(x, y1, width, label='Testset', color='#1f77b4', edgecolor='black')
plt.bar(x, y2, width, label='Trainset', bottom=y1, color='#ff7f0e', edgecolor='black')

plt.xlabel('Categories')
plt.ylabel('Numbers')
plt.grid(True, linestyle='--', alpha=0.6, axis='y')

plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fancybox=True, framealpha=0.5, fontsize=10)

plt.savefig('Number of images in each category.pdf', dpi=120, bbox_inches='tight')

plt.show()

!dir

"""# Train model"""

import os
# Store the output file
os.mkdir('/content/drive/MyDrive/Colab Notebooks/Projects/output')

# Store the trained model weights
os.mkdir('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint')

# Store the generated diagram
os.mkdir('/content/drive/MyDrive/Colab Notebooks/Projects/diagram')

# Commented out IPython magic to ensure Python compatibility.
import time
import os
from tqdm import tqdm

import pandas as pd
import numpy as np

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F

import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

# Get computing hardware
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print('device', device)

"""* Image preprocessing"""

from torchvision import transforms

# Training dataset image preprocessing: resizing and cropping, image augmentation, converting to Tensor, normalization
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ColorJitter(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
# Testing dataset image preprocessing -RCTN: Resizing, cropping, converting to Tensor, normalization
test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

"""* Load datasets"""

dataset_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split'

train_path = os.path.join(dataset_dir, 'train')
test_path = os.path.join(dataset_dir, 'test')
print('Training set path', train_path)
print('Testing set path', test_path)

from torchvision import datasets
# Load the training set
train_dataset = datasets.ImageFolder(train_path, train_transform)
# Load the testing set
test_dataset = datasets.ImageFolder(test_path, test_transform)

print('Number of images in the training set:', len(train_dataset))
print('Number of classes:', len(train_dataset.classes))
print('Class names:', train_dataset.classes)
print('Number of images in the testing set:', len(test_dataset))
print('Number of classes:', len(test_dataset.classes))
print('Class names:', test_dataset.classes)

"""* Create mappings between the class names and their respective indices in the dataset
* These mappings facilitate the conversion between human-readable class names and their corresponding numerical indices, ensuring seamless handling and interpretation of classes during model training, evaluation, and inference.
"""

# List of class names
class_names = train_dataset.classes
n_class = len(class_names)
# Mapping: Class to index
class_to_idx = train_dataset.class_to_idx

# Mapping: Index to class
idx_to_labels = {y: x for x, y in train_dataset.class_to_idx.items()}
idx_to_labels

# Save as npy file
np.save('/content/drive/MyDrive/Colab Notebooks/Projects/idx_to_labels.npy', idx_to_labels)
np.save('/content/drive/MyDrive/Colab Notebooks/Projects/labels_to_idx.npy', train_dataset.class_to_idx)

"""* Define a 'DataLoader'"""

from torch.utils.data import DataLoader

BATCH_SIZE = 32

# Data loader for the training set
train_loader = DataLoader(train_dataset,
              batch_size=BATCH_SIZE,
              shuffle=True,
              num_workers=4
              )

# Data loader for the testing set
test_loader = DataLoader(test_dataset,
              batch_size=BATCH_SIZE,
              shuffle=False,
              num_workers=4
              )

"""* Retrieve a batch of images and their corresponding labels"""

images, labels = next(iter(train_loader))

# Print the shape of the batch of images
print(images.shape)

# Print the labels of the batch
print(labels)

# Visualize a batch of images and their labels
# Convert Tensor tensors from the dataset to numpy arrays
images = images.numpy()

# Check the shape of a single image
print(images[4].shape)

# Display a histogram of pixel values in a single image
plt.hist(images[4].flatten(), bins=50)
plt.show()

# Display preprocessed images from the batch
idx = 2
# Displaying an image after transposing the dimensions to (224, 224, 3)
plt.imshow(images[idx].transpose((1, 2, 0)))  # Convert to (224, 224, 3)
plt.title('label:' + str(labels[idx].item()))
plt.show()

label = labels[idx].item()
label

pred_classname = idx_to_labels[label]
pred_classname

# Displaying the original image
idx = 2
mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])
plt.imshow(np.clip(images[idx].transpose((1, 2, 0)) * std + mean, 0, 1))
plt.title('label:' + pred_classname)
plt.show()

"""# Transfer learning"""

from torchvision import models
import torch.optim as optim
from torchsummary import summary

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, n_class)
model = model.to(device)

input_data = torch.randn((1, 3, 224, 224)).to(device)

summary(model, input_data.shape[1:], device=str(device))

"""* Training configuration"""

model = models.resnet18(pretrained=True) # Load the pre-trained model

model.fc = nn.Linear(model.fc.in_features, n_class)
model.fc

optimizer = optim.Adam(model.fc.parameters())

# Transfer the model to the specified device (e.g., GPU if available)
model = model.to(device)

# Define the cross-entropy loss function
criterion = nn.CrossEntropyLoss()

# Learning rate adjustment strategy
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

# Number of training epochs
EPOCHS = 20

"""* Simulate a batch of training"""

# Get a batch of data and labels
images, labels = next(iter(train_loader))
images = images.to(device)
labels = labels.to(device)

# Input the batch to the model, perform forward pass prediction
outputs = model(images)

# Get the predicted class scores (logits) for all images in the current batch
outputs.shape

# Calculate the average cross-entropy loss for each sample in the current batch using logits
loss = criterion(outputs, labels)

# Backpropagation steps
optimizer.zero_grad()  # Clear gradients
loss.backward()  # Backpropagation
optimizer.step()  # Optimizer update

# Get the predicted classes for all images in the current batch
_, preds = torch.max(outputs, 1)

preds

labels

"""* Training model"""

# Iterate through each epoch
for epoch in tqdm(range(EPOCHS)):

    model.train()  # Set the model to training mode

    for images, labels in train_loader:  # Get a batch containing data and labels from the training set
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)       # Perform forward pass to get predictions for the current batch
        loss = criterion(outputs, labels)  # Calculate the cross-entropy loss for the current batch by comparing predictions with labels

        optimizer.zero_grad() # Clear previously computed gradients
        loss.backward()    # Backpropagate the loss to compute gradients of neural network weights
        optimizer.step()   # Update neural network weights using optimization algorithm

"""* Test"""

model.eval()  # Set the model to evaluation mode
with torch.no_grad():  # Disable gradient calculation

    correct = 0
    total = 0

    for images, labels in tqdm(test_loader):  # Get a batch containing data and labels from the test set
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)  # Perform forward pass to get predictions (confidence) for the current batch
        _, preds = torch.max(outputs, 1)  # Get the predicted class with the highest confidence as the prediction
        total += labels.size(0)
        correct += (preds == labels).sum()  # Count correctly predicted samples

    accuracy = 100 * correct / total
    print('Accuracy on the test set: {:.3f} %'.format(accuracy))

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models

# Number of training epochs
EPOCHS = 50

train_losses = []  # List to store training losses
test_losses = []  # List to store test losses
train_accuracies = []  # List to store training accuracies
test_accuracies = []  # List to store test accuracies

for epoch in range(EPOCHS):
    model.train()  # Set the model to training mode
    running_train_loss = 0.0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_train_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    epoch_train_loss = running_train_loss / len(train_loader)
    train_losses.append(epoch_train_loss)

    train_accuracy = 100 * correct_train / total_train
    train_accuracies.append(train_accuracy)

    # Testing the model
    model.eval()
    running_test_loss = 0.0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            running_test_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

        epoch_test_loss = running_test_loss / len(test_loader)
        test_losses.append(epoch_test_loss)

        test_accuracy = 100 * correct_test / total_test
        test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    scheduler.step(epoch_test_loss)

# Plotting loss and accuracy graphs
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

# Plotting loss
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

# Plotting accuracy
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

import itertools
import matplotlib.pyplot as plt
import numpy as np
import torch
from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(model, test_loader, class_names):
    model.eval()  # Set the model to evaluation mode
    device = next(model.parameters()).device  # Get the device the model is on

    all_preds = []
    all_labels = []

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)  # Perform forward pass to get predictions
            _, preds = torch.max(outputs, 1)  # Get predicted classes
            all_preds.extend(preds.cpu().numpy())  # Append predictions
            all_labels.extend(labels.cpu().numpy())  # Append labels

    cm = confusion_matrix(all_labels, all_preds)  # Calculate confusion matrix

    plt.figure(figsize=(10, 8))
    plt.imshow(cm, interpolation='nearest', cmap='Reds')
    plt.colorbar()

    ticks = np.arange(len(class_names))
    plt.xticks(ticks, class_names, rotation=90)
    plt.yticks(ticks, class_names)

    plt.title('Confusion Matrix')

    threshold = 4
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, "{:,}".format(cm[i, j]),
                 horizontalalignment='center',
                 color='white' if cm[i, j] > threshold else 'black')

    plt.tight_layout()
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')

class_names = train_dataset.classes

plot_confusion_matrix(model, test_loader, class_names)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import torch
num_classes = 5;

def generate_roc_curve(model, test_loader, num_classes):
    model.eval()  # Set the model to evaluation mode
    device = next(model.parameters()).device  # Get the device the model is on

    all_preds = []
    all_labels = []

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)  # Perform forward pass to get predictions
            all_preds.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())  # Append predictions
            all_labels.extend(labels.cpu().numpy())  # Append labels

    y_pred = np.array(all_preds)
    y_true = np.array(all_labels)

    # Convert labels to one-hot encoding
    y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))

    # Compute ROC curve and ROC area for each class
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve(y_true_one_hot[:, i], y_pred[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Plot ROC curves
    plt.figure(figsize=(8, 6))
    for i in range(num_classes):
        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

    plt.plot([0, 1], [0, 1], 'k--', linewidth=2)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve for Multi-Class Classification')
    plt.legend(loc='lower right')
    plt.show()

generate_roc_curve(model, test_loader, num_classes)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, auc
from sklearn.preprocessing import label_binarize
import torch

def generate_precision_recall_curve(model, test_loader, num_classes):
    model.eval()  # Set the model to evaluation mode
    device = next(model.parameters()).device  # Get the device the model is on

    all_preds = []
    all_labels = []

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)  # Perform forward pass to get predictions
            all_preds.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())  # Append predictions
            all_labels.extend(labels.cpu().numpy())  # Append labels

    y_pred = np.array(all_preds)
    y_true = np.array(all_labels)

    # Convert labels to one-hot encoding
    y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))

    # Compute precision and recall for each class
    precision = dict()
    recall = dict()
    pr_auc = dict()

    for i in range(num_classes):
        precision[i], recall[i], _ = precision_recall_curve(y_true_one_hot[:, i], y_pred[:, i])
        pr_auc[i] = auc(recall[i], precision[i])

    # Plot Precision-Recall curves
    plt.figure(figsize=(8, 6))
    for i in range(num_classes):
        plt.plot(recall[i], precision[i], label=f'Class {i} (AUC = {pr_auc[i]:.2f})')

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve for Multi-Class Classification')
    plt.legend(loc='lower right')
    plt.show()

generate_precision_recall_curve(model, test_loader, num_classes)

torch.save(model, '/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/resnet_18_model.pth')

"""# MobileNetV2"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, models, datasets
from torchsummary import summary
from tqdm import tqdm
import matplotlib.pyplot as plt

# Define the number of classes
n_class = 5

# Define the MobileNetV2-based model
class MobileNetV2Model(nn.Module):
    def __init__(self, num_classes):
        super(MobileNetV2Model, self).__init__()
        self.mobilenetv2 = models.mobilenet_v2(pretrained=True)
        in_features = self.mobilenetv2.classifier[1].in_features
        self.mobilenetv2.classifier[1] = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.mobilenetv2(x)

# Set up data transformations
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Load the training and testing sets
train_dataset = datasets.ImageFolder(train_path, train_transform)
test_dataset = datasets.ImageFolder(test_path, test_transform)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

# Instantiate the MobileNetV2 model
mobile_net_v2_model = MobileNetV2Model(num_classes=n_class)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
mobile_net_v2_model = mobile_net_v2_model.to(device)

# Print the model summary
summary(mobile_net_v2_model, input_size=(3, 224, 224), device=str(device))

# Define the optimizer and loss function
optimizer_mobile_net = optim.Adam(mobile_net_v2_model.parameters())
criterion_mobile_net = nn.CrossEntropyLoss()

# Number of training epochs
EPOCHS_MOBILE_NET = 50

train_losses = []  # List to store training losses
test_losses = []   # List to store testing losses
train_accuracies = []  # List to store training accuracies
test_accuracies = []   # List to store testing accuracies

best_test_loss = float('inf')  # Initialize with a very large value
early_stop_patience = 5  # Patience for early stopping
counter = 0  # Counter for early stopping

# Training loop for MobileNetV2
for epoch in tqdm(range(EPOCHS_MOBILE_NET)):
    mobile_net_v2_model.train()
    running_train_loss = 0.0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer_mobile_net.zero_grad()
        outputs = mobile_net_v2_model(images)
        loss = criterion_mobile_net(outputs, labels)
        loss.backward()
        optimizer_mobile_net.step()

        running_train_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    epoch_train_loss = running_train_loss / len(train_loader)
    train_losses.append(epoch_train_loss)

    train_accuracy = 100 * correct_train / total_train
    train_accuracies.append(train_accuracy)

    # Testing the model
    mobile_net_v2_model.eval()
    running_test_loss = 0.0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = mobile_net_v2_model(images)
            loss = criterion_mobile_net(outputs, labels)
            running_test_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

        epoch_test_loss = running_test_loss / len(test_loader)
        test_losses.append(epoch_test_loss)

        test_accuracy = 100 * correct_test / total_test
        test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS_MOBILE_NET}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    # Early stopping
    if epoch_test_loss < best_test_loss:
        best_test_loss = epoch_test_loss
        counter = 0
    else:
        counter += 1
        if counter >= early_stop_patience:
            print("Early stopping triggered!")
            break

# Plotting loss and accuracy graphs
plt.figure(figsize=(12, 5))

# Plotting loss
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

# Plotting accuracy
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, models, datasets
from torchsummary import summary
from tqdm import tqdm

# Define the number of classes
n_class = 5

# Define the MobileNetV2-based model
class MobileNetV2Model(nn.Module):
    def __init__(self, num_classes):
        super(MobileNetV2Model, self).__init__()
        self.mobilenetv2 = models.mobilenet_v2(pretrained=True)
        in_features = self.mobilenetv2.classifier[1].in_features
        self.mobilenetv2.classifier[1] = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.mobilenetv2(x)

# Set up data transformations
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Load the training and testing sets
train_dataset = datasets.ImageFolder(train_path, train_transform)
test_dataset = datasets.ImageFolder(test_path, test_transform)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

# Instantiate the MobileNetV2 model
mobile_net_v2_model = MobileNetV2Model(num_classes=n_class)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
mobile_net_v2_model = mobile_net_v2_model.to(device)

# Print the model summary
summary(mobile_net_v2_model, input_size=(3, 224, 224), device=str(device))

# Define the optimizer and loss function
optimizer_mobile_net = optim.Adam(mobile_net_v2_model.parameters())
criterion_mobile_net = nn.CrossEntropyLoss()

# Number of training epochs
EPOCHS_MOBILE_NET = 20

# Training loop for MobileNetV2
for epoch in tqdm(range(EPOCHS_MOBILE_NET)):
    mobile_net_v2_model.train()

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer_mobile_net.zero_grad()
        outputs = mobile_net_v2_model(images)
        loss = criterion_mobile_net(outputs, labels)
        loss.backward()
        optimizer_mobile_net.step()

# Evaluation on the test set
mobile_net_v2_model.eval()
correct_mobile_net = 0
total_mobile_net = 0

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = mobile_net_v2_model(images)
        _, preds = torch.max(outputs, 1)
        total_mobile_net += labels.size(0)
        correct_mobile_net += (preds == labels).sum().item()

accuracy_mobile_net = correct_mobile_net / total_mobile_net * 100
print('MobileNetV2 Accuracy on the test set: {:.2f}%'.format(accuracy_mobile_net))

# Save trained MobileNetV2 model
torch.save(mobile_net_v2_model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/mobile_net_v2_model.pth')

# Load trained MobileNetV2 model
loaded_mobile_net_v2_model = MobileNetV2Model(num_classes=5)
loaded_mobile_net_v2_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/mobile_net_v2_model.pth'))
loaded_mobile_net_v2_model.eval()

"""# InceptionV3"""

# Commented out IPython magic to ensure Python compatibility.
import time
import os
from tqdm import tqdm

import pandas as pd
import numpy as np

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F

import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

from torchvision import transforms

# Training dataset image preprocessing: resizing and cropping, image augmentation, converting to Tensor, normalization
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
# Testing dataset image preprocessing -RCTN: Resizing, cropping, converting to Tensor, normalization
test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
dataset_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split'
train_path = os.path.join(dataset_dir, 'train')
test_path = os.path.join(dataset_dir, 'test')
print('Training set path', train_path)
print('Testing set path', test_path)

from torchvision import datasets
# Load the training set
train_dataset = datasets.ImageFolder(train_path, train_transform)
# Load the testing set
test_dataset = datasets.ImageFolder(test_path, test_transform)

print('Number of images in the training set:', len(train_dataset))
print('Number of classes:', len(train_dataset.classes))
print('Class names:', train_dataset.classes)
print('Number of images in the testing set:', len(test_dataset))
print('Number of classes:', len(test_dataset.classes))
print('Class names:', test_dataset.classes)

from torch.utils.data import DataLoader

BATCH_SIZE = 32

# Data loader for the training set
train_loader = DataLoader(train_dataset,
              batch_size=BATCH_SIZE,
              shuffle=True,
              num_workers=4
              )

# Data loader for the testing set
test_loader = DataLoader(test_dataset,
              batch_size=BATCH_SIZE,
              shuffle=False,
              num_workers=4
              )

import torch

print(torch.__version__)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, models, datasets
from torchsummary import summary
from tqdm import tqdm
import matplotlib.pyplot as plt

# Define the number of classes
n_class = len(train_dataset.classes)

# Define the InceptionV3-based model
class InceptionV3Model(nn.Module):
    def __init__(self, num_classes):
        super(InceptionV3Model, self).__init__()
        self.inceptionv3 = models.inception_v3(pretrained=True)
        in_features = self.inceptionv3.fc.in_features
        self.inceptionv3.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.inceptionv3(x)

# Set up data transformations
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(299),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(320),
    transforms.CenterCrop(299),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Load the training and testing sets
train_dataset = datasets.ImageFolder(train_path, train_transform)
test_dataset = datasets.ImageFolder(test_path, test_transform)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

# Instantiate the InceptionV3 model
inceptionv3_model = InceptionV3Model(num_classes=n_class)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
inceptionv3_model = inceptionv3_model.to(device)

# Print the model summary
summary(inceptionv3_model, input_size=(3, 299, 299), device=str(device))

# Define the optimizer and loss function
optimizer_inceptionv3 = optim.Adam(inceptionv3_model.parameters())
criterion_inceptionv3 = nn.CrossEntropyLoss()

# Number of training epochs
EPOCHS_INCEPTIONV3 = 50

train_losses = []  # List to store training losses
test_losses = []   # List to store testing losses
train_accuracies = []  # List to store training accuracies
test_accuracies = []   # List to store testing accuracies

best_test_loss = float('inf')  # Initialize with a very large value
early_stop_patience = 5  # Patience for early stopping
counter = 0  # Counter for early stopping

# Training loop for InceptionV3
for epoch in tqdm(range(EPOCHS_INCEPTIONV3)):
    inceptionv3_model.train()
    running_train_loss = 0.0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer_inceptionv3.zero_grad()
        outputs, _ = inceptionv3_model(images)
        loss = criterion_inceptionv3(outputs, labels)
        loss.backward()
        optimizer_inceptionv3.step()

        running_train_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    epoch_train_loss = running_train_loss / len(train_loader)
    train_losses.append(epoch_train_loss)
    train_accuracy = 100 * correct_train / total_train
    train_accuracies.append(train_accuracy)

    # Testing the model
    inceptionv3_model.eval()
    running_test_loss = 0.0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = inceptionv3_model(images)
            loss = criterion_inceptionv3(outputs, labels)
            running_test_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

        epoch_test_loss = running_test_loss / len(test_loader)
        test_losses.append(epoch_test_loss)
        test_accuracy = 100 * correct_test / total_test
        test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS_INCEPTIONV3}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    # Early stopping
    if epoch_test_loss < best_test_loss:
        best_test_loss = epoch_test_loss
        counter = 0
    else:
        counter += 1
        if counter >= early_stop_patience:
            print("Early stopping triggered!")
            break

# Plotting loss and accuracy graphs
plt.figure(figsize=(12, 5))

# Plotting loss
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

# Plotting accuracy
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, models, datasets
from torchsummary import summary
from tqdm import tqdm

# Define the number of classes
n_class = len(train_dataset.classes)

# Define the InceptionV3-based model
class InceptionV3Model(nn.Module):
    def __init__(self, num_classes):
        super(InceptionV3Model, self).__init__()
        self.inceptionv3 = models.inception_v3(pretrained=True)
        in_features = self.inceptionv3.fc.in_features
        self.inceptionv3.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.inceptionv3(x)

# Set up data transformations
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(299),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(320),
    transforms.CenterCrop(299),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Load the training and testing sets
train_dataset = datasets.ImageFolder(train_path, train_transform)
test_dataset = datasets.ImageFolder(test_path, test_transform)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

# Instantiate the InceptionV3 model
inceptionv3_model = InceptionV3Model(num_classes=n_class)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
inceptionv3_model = inceptionv3_model.to(device)

# Print the model summary
summary(inceptionv3_model, input_size=(3, 299, 299), device=str(device))

# Define the optimizer and loss function
optimizer_inceptionv3 = optim.Adam(inceptionv3_model.parameters())
criterion_inceptionv3 = nn.CrossEntropyLoss()

# Number of training epochs
EPOCHS_INCEPTIONV3 = 3

# Training loop for InceptionV3
for epoch in tqdm(range(EPOCHS_INCEPTIONV3)):
    inceptionv3_model.train()

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer_inceptionv3.zero_grad()

        # Get the outputs (logits) from the main classifier
        outputs, aux_outputs = inceptionv3_model(images)

        # Calculate the loss using the main logits
        loss = criterion_inceptionv3(outputs, labels)

        # Backpropagation and optimization
        loss.backward()
        optimizer_inceptionv3.step()


# Evaluation on the test set
inceptionv3_model.eval()
correct_inceptionv3 = 0
total_inceptionv3 = 0

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = inceptionv3_model(images)
        _, preds = torch.max(outputs, 1)
        total_inceptionv3 += labels.size(0)
        correct_inceptionv3 += (preds == labels).sum().item()

accuracy_inceptionv3 = correct_inceptionv3 / total_inceptionv3 * 100
print('InceptionV3 Accuracy on the test set: {:.2f}%'.format(accuracy_inceptionv3))

# Save trained InceptionV3 model
torch.save(inceptionv3_model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/inceptionv3_model2.pth')

# Load trained InceptionV3 model
loaded_mobile_net_v2_model = MobileNetV2Model(num_classes=5)
loaded_mobile_net_v2_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/inceptionv3_model2.pth'))
loaded_mobile_net_v2_model.eval()

"""# Ensemble learning(fail)"""

import torch
import torch.nn as nn
import torch.optim as optim
import os
import matplotlib.pyplot as plt

from torch.utils.data import DataLoader
from torchvision import transforms, models, datasets
# from torchsummary import summary
from tqdm import tqdm

# Define the number of classes
n_class = len(train_dataset.classes)

# Define the MobileNetV2-based model
class MobileNetV2Model(nn.Module):
    def __init__(self, num_classes):
        super(MobileNetV2Model, self).__init__()
        self.mobilenetv2 = models.mobilenet_v2(pretrained=True)
        in_features = self.mobilenetv2.classifier[1].in_features
        self.mobilenetv2.classifier[1] = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.mobilenetv2(x)

# Define the InceptionV3-based model
class InceptionV3Model(nn.Module):
    def __init__(self, num_classes):
        super(InceptionV3Model, self).__init__()
        self.inceptionv3 = models.inception_v3(pretrained=True)
        in_features = self.inceptionv3.fc.in_features
        self.inceptionv3.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.inceptionv3(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load trained MobileNetV2 model
loaded_mobile_net_v2_model = MobileNetV2Model(num_classes=n_class)
loaded_mobile_net_v2_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/mobile_net_v2_model.pth', map_location=device))
loaded_mobile_net_v2_model = loaded_mobile_net_v2_model.to(device)
loaded_mobile_net_v2_model.eval()

# Load trained InceptionV3 model
loaded_inceptionv3_model = InceptionV3Model(num_classes=n_class)
loaded_inceptionv3_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/inceptionv3_model2.pth', map_location=device))
loaded_inceptionv3_model = loaded_inceptionv3_model.to(device)
loaded_inceptionv3_model.eval()

# Load trained ResNet model
resnet_model = torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/resnet_18_model.pth', map_location=device)
resnet_model.eval()

# Data loader for the testing set
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

# Initialize counters
correct_ensemble = 0
total_ensemble = 0

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        # Get predictions from each loaded model
        outputs_mobile_net = loaded_mobile_net_v2_model(images)
        outputs_inceptionv3 = loaded_inceptionv3_model(images)
        outputs_resnet = resnet_model(images)

        # Perform voting to get the final prediction
        ensemble_preds = torch.argmax(outputs_mobile_net + outputs_inceptionv3 + outputs_resnet, dim=1)

        total_ensemble += labels.size(0)
        correct_ensemble += (ensemble_preds == labels).sum().item()

# Calculate accuracy for the ensemble model
accuracy_ensemble = correct_ensemble / total_ensemble * 100
print('Ensemble Model Accuracy on the test set: {:.2f}%'.format(accuracy_ensemble))

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

loaded_ensemble_model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        # Get predictions from the loaded ensemble model
        outputs_mobile_net = loaded_mobile_net_v2_model(images)
        outputs_inceptionv3 = loaded_inceptionv3_model(images)
        outputs_resnet = resnet_model(images)

        # Forward pass through the loaded ensemble model
        outputs_ensemble = loaded_ensemble_model(outputs_mobile_net, outputs_inceptionv3, outputs_resnet)

        # Get the predicted class with the highest confidence as the prediction
        _, preds = torch.max(outputs_ensemble, 1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Create a confusion matrix
conf_matrix = confusion_matrix(all_labels, all_preds)

# Display the confusion matrix using seaborn
plt.figure(figsize=(10, 8))
class_labels = train_dataset.classes
sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Set the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

loaded_mobile_net_v2_model.train()
loaded_inceptionv3_model.train()
resnet_model.train()

# Early stopping parameters
early_stop_patience = 5
best_test_loss = float('inf')
counter = 0

# Number of training epochs
EPOCHS = 50

train_losses = []  # List to store training losses
test_losses = []  # List to store test losses
train_accuracies = []  # List to store training accuracies
test_accuracies = []  # List to store test accuracies

# Define the number of classes
n_class = len(train_dataset.classes)
num_classes = n_class

class EnsembleModel(nn.Module):
    def __init__(self, input_sizes, num_classes):
        super(EnsembleModel, self).__init__()
        self.fc1 = nn.Linear(sum(input_sizes), 512)
        self.dropout = nn.Dropout(0.5)  # Dropout layer with a dropout rate of 0.5
        self.fc2 = nn.Linear(512, num_classes)

    def forward(self, input1, input2, input3):
        x = torch.cat([input1, input2, input3], dim=1)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)  # Apply dropout
        x = self.fc2(x)
        return x


input_sizes = [1280, 2048, 512]

# Instantiate the ensemble model and move it to device
ensemble_model = EnsembleModel(input_sizes, num_classes=num_classes)
ensemble_model = ensemble_model.to(device)

# Define loss function and optimizer (adjust hyperparameters as needed)
criterion = torch.nn.CrossEntropyLoss().to(device)
optimizer = optim.Adam(ensemble_model.parameters(), lr=0.01)

# Define learning rate scheduler
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)

# Early stopping parameters
early_stop_patience = 8
best_test_loss = float('inf')
counter = 0

# Training loop
for epoch in range(EPOCHS):
    ensemble_model.train()  # Set the model to training mode
    running_train_loss = 0.0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()

        # Get predictions from the loaded ensemble model
        outputs_mobile_net = loaded_mobile_net_v2_model(images)
        outputs_inceptionv3 = loaded_inceptionv3_model(images)
        outputs_resnet = resnet_model(images)

        # Forward pass through the loaded ensemble model
        outputs_ensemble = ensemble_model(outputs_mobile_net, outputs_inceptionv3, outputs_resnet)

        loss = criterion(outputs_ensemble, labels)
        loss.backward()
        optimizer.step()

        running_train_loss += loss.item()
        _, predicted = torch.max(outputs_ensemble.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    epoch_train_loss = running_train_loss / len(train_loader)
    train_losses.append(epoch_train_loss)
    train_accuracy = 100 * correct_train / total_train
    train_accuracies.append(train_accuracy)

    # Testing the model
    ensemble_model.eval()
    running_test_loss = 0.0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            # Get predictions from the loaded ensemble model
            outputs_mobile_net = loaded_mobile_net_v2_model(images)
            outputs_inceptionv3 = loaded_inceptionv3_model(images)
            outputs_resnet = resnet_model(images)

            # Forward pass through the loaded ensemble model
            outputs_ensemble = ensemble_model(outputs_mobile_net, outputs_inceptionv3, outputs_resnet)

            loss = criterion(outputs_ensemble, labels)
            running_test_loss += loss.item()

            _, predicted = torch.max(outputs_ensemble.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

        epoch_test_loss = running_test_loss / len(test_loader)
        test_losses.append(epoch_test_loss)
        test_accuracy = 100 * correct_test / total_test
        test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    # Updating the learning rate
    scheduler.step(epoch_test_loss)

    # Early stopping
    if epoch_test_loss < best_test_loss:
        best_test_loss = epoch_test_loss
        counter = 0
        # Save the best model weights
        torch.save(ensemble_model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/best_ensemble_model.pth')
    else:
        counter += 1
        if counter >= early_stop_patience:
            print("Early stopping triggered!")
            break

# Plotting loss and accuracy graphs
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

# Plotting loss
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

# Plotting accuracy
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Save the entire model
import os
os.makedirs('models', exist_ok=True)
torch.save(ensemble_model, 'models/ensemble_model.pth')

# Load the saved ensemble model
loaded_ensemble_model = torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/ensemble_model.pth')
loaded_ensemble_model.eval()

"""# Ensemble Learning(fail)

"""

# Commented out IPython magic to ensure Python compatibility.
import time
import os
from tqdm import tqdm

import pandas as pd
import numpy as np

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F

import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

from torchvision import transforms

# Training dataset image preprocessing: resizing and cropping, image augmentation, converting to Tensor, normalization
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
# Testing dataset image preprocessing -RCTN: Resizing, cropping, converting to Tensor, normalization
test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
dataset_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split'
train_path = os.path.join(dataset_dir, 'train')
test_path = os.path.join(dataset_dir, 'test')
print('Training set path', train_path)
print('Testing set path', test_path)

from torchvision import datasets
# Load the training set
train_dataset = datasets.ImageFolder(train_path, train_transform)
# Load the testing set
test_dataset = datasets.ImageFolder(test_path, test_transform)

print('Number of images in the training set:', len(train_dataset))
print('Number of classes:', len(train_dataset.classes))
print('Class names:', train_dataset.classes)
print('Number of images in the testing set:', len(test_dataset))
print('Number of classes:', len(test_dataset.classes))
print('Class names:', test_dataset.classes)

import torch
import torch.nn as nn
from torchvision import models, datasets, transforms
from torch.utils.data import DataLoader

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

train_transform = transforms.Compose([
    transforms.RandomResizedCrop(299),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(320),
    transforms.CenterCrop(299),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_dataset = datasets.ImageFolder(train_path, train_transform)
test_dataset = datasets.ImageFolder(test_path, test_transform)

BATCH_SIZE = 32

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

class MobileNetV2Model(nn.Module):
    def __init__(self, num_classes):
        super(MobileNetV2Model, self).__init__()
        self.mobilenetv2 = models.mobilenet_v2(pretrained=True)
        in_features = self.mobilenetv2.classifier[1].in_features
        self.mobilenetv2.classifier[1] = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.mobilenetv2(x)

class InceptionV3Model(nn.Module):
    def __init__(self, num_classes):
        super(InceptionV3Model, self).__init__()
        self.inceptionv3 = models.inception_v3(pretrained=True)
        in_features = self.inceptionv3.fc.in_features
        self.inceptionv3.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.inceptionv3(x)

n_class = len(train_dataset.classes)

loaded_mobile_net_v2_model = MobileNetV2Model(num_classes=n_class)
loaded_mobile_net_v2_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/mobile_net_v2_model.pth', map_location=device))
loaded_mobile_net_v2_model = loaded_mobile_net_v2_model.to(device)
loaded_mobile_net_v2_model.eval()

loaded_inceptionv3_model = InceptionV3Model(num_classes=n_class)
loaded_inceptionv3_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/inceptionv3_model2.pth', map_location=device))
loaded_inceptionv3_model = loaded_inceptionv3_model.to(device)
loaded_inceptionv3_model.eval()

resnet_model = torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/resnet_18_model.pth', map_location=device)
resnet_model = resnet_model.to(device)
resnet_model.eval()

def evaluate_model(model, test_loader):
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    return accuracy

resnet_accuracy = evaluate_model(resnet_model, test_loader)
mobilenet_accuracy = evaluate_model(loaded_mobile_net_v2_model, test_loader)
inception_accuracy = evaluate_model(loaded_inceptionv3_model, test_loader)

total_accuracy = resnet_accuracy + mobilenet_accuracy + inception_accuracy
weights = [resnet_accuracy / total_accuracy, mobilenet_accuracy / total_accuracy, inception_accuracy / total_accuracy]

print(f'ResNet Accuracy: {resnet_accuracy}%')
print(f'MobileNetV2 Accuracy: {mobilenet_accuracy}%')
print(f'InceptionV3 Accuracy: {inception_accuracy}%')
print(f'Weights: {weights}')

import matplotlib.pyplot as plt
import numpy as np

model_names = ['ResNet', 'MobileNetV2', 'InceptionV3']

accuracies = [resnet_accuracy, mobilenet_accuracy, inception_accuracy]

model_weights = weights

plt.figure(figsize=(10, 6))

fig, ax1 = plt.subplots()

ax1.bar(model_names, accuracies, color='b', alpha=0.6, label='Accuracy')
ax1.set_xlabel('Model')
ax1.set_ylabel('Accuracy (%)', color='b')
ax1.tick_params('y', colors='b')

ax2 = ax1.twinx()
ax2.plot(model_names, model_weights, color='r', marker='o', label='Weight', linewidth=2)
ax2.set_ylabel('Weight', color='r')
ax2.tick_params('y', colors='r')

ax1.legend(loc='upper left')
ax2.legend(loc='upper right')

plt.title('Model Performance and Weights')
plt.show()

"""# Ensemble Module"""

import torch
import itertools
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import os
import numpy as np
from torchvision.models.inception import InceptionOutputs
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import average_precision_score
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize

from itertools import cycle
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Set up data transformations
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(299),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(320),
    transforms.CenterCrop(299),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

dataset_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split'
train_path = os.path.join(dataset_dir, 'train')
test_path = os.path.join(dataset_dir, 'test')

train_dataset = datasets.ImageFolder(train_path, train_transform)
test_dataset = datasets.ImageFolder(test_path, test_transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)

# List of class names
class_names = train_dataset.classes
n_class = len(class_names)
# Mapping: Class to index
class_to_idx = train_dataset.class_to_idx

# Mapping: Index to class
idx_to_labels = {y: x for x, y in train_dataset.class_to_idx.items()}
idx_to_labels

# model defination
class MobileNetV2Model(nn.Module):
    def __init__(self, num_classes):
        super(MobileNetV2Model, self).__init__()
        self.mobilenetv2 = models.mobilenet_v2(pretrained=True)
        self.mobilenetv2.classifier[1] = nn.Linear(self.mobilenetv2.classifier[1].in_features, num_classes)

    def forward(self, x):
        return self.mobilenetv2(x)

class InceptionV3Model(nn.Module):
    def __init__(self, num_classes):
        super(InceptionV3Model, self).__init__()
        self.inceptionv3 = models.inception_v3(pretrained=True)
        in_features = self.inceptionv3.fc.in_features
        self.inceptionv3.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.inceptionv3(x)

# Model loading
n_class = len(train_dataset.classes)

loaded_mobile_net_v2_model = MobileNetV2Model(num_classes=n_class)
loaded_mobile_net_v2_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/mobile_net_v2_model.pth', map_location=device))
loaded_mobile_net_v2_model = loaded_mobile_net_v2_model.to(device)
loaded_mobile_net_v2_model.eval()

loaded_inceptionv3_model = InceptionV3Model(num_classes=n_class)
loaded_inceptionv3_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/inceptionv3_model2.pth', map_location=device))
loaded_inceptionv3_model = loaded_inceptionv3_model.to(device)
loaded_inceptionv3_model.eval()

resnet_model = torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/resnet_18_model.pth', map_location=device)
resnet_model = resnet_model.to(device)
resnet_model.eval()

# class EnsembleModel(nn.Module):
#     def __init__(self, modelA, modelB, modelC, weights):
#         super(EnsembleModel, self).__init__()
#         self.modelA = modelA
#         self.modelB = modelB
#         self.modelC = modelC
#         self.weights = torch.tensor(weights, device=device, dtype=torch.float32)

#     def forward(self, x):
#         outputA = self.modelA(x)
#         outputB = self.modelB(x)
#         outputC = self.modelC(x)

#         # Ensure outputs are weighted and summed appropriately
#         output = (self.weights[0] * outputA +
#                   self.weights[1] * outputB +
#                   self.weights[2] * outputC)
#         return output

class EnsembleModel(nn.Module):
    def __init__(self, modelA, modelB, modelC, weights):
        super(EnsembleModel, self).__init__()
        self.modelA = modelA
        self.modelB = modelB
        self.modelC = modelC
        self.weights = torch.tensor(weights, device=device, dtype=torch.float32)

    def forward(self, x):
        outputA = self.modelA(x)
        outputB = self.modelB(x)
        outputC = self.modelC(x)

        # Check and process the output of the InceptionV3 model
        if isinstance(outputB, InceptionOutputs):
            outputB = outputB.logits  # Extract the main output

        output = (self.weights[0] * outputA +
                  self.weights[1] * outputB +
                  self.weights[2] * outputC)

        return output

def evaluate_model(model, test_loader):
    model.eval()  # Ensures the model is in evaluation mode.
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            # Direct handling for InceptionV3 output format
            if hasattr(outputs, 'logits'):
                outputs = outputs.logits
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    return accuracy

# Evaluation functions
def evaluate_model(model, test_loader):
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return 100 * correct / total

# Each model is evaluated and weights are calculated
resnet_accuracy = evaluate_model(resnet_model, test_loader)
mobilenet_accuracy = evaluate_model(loaded_mobile_net_v2_model, test_loader)
inception_accuracy = evaluate_model(loaded_inceptionv3_model, test_loader)

total_accuracy = resnet_accuracy + mobilenet_accuracy + inception_accuracy
weights = [resnet_accuracy / total_accuracy, mobilenet_accuracy / total_accuracy, inception_accuracy / total_accuracy]

# Model names
model_names = ['ResNet', 'MobileNetV2', 'InceptionV3']

# Accuracies
accuracies = [resnet_accuracy, mobilenet_accuracy, inception_accuracy]

# Creating subplots
fig, axs = plt.subplots(1, 2, figsize=(14, 5))

# Plotting accuracies
axs[0].bar(model_names, accuracies, color=['blue', 'green', 'red'])
axs[0].set_title('Model Accuracies')
axs[0].set_ylabel('Accuracy (%)')
axs[0].set_ylim(0, 100)  # Assuming accuracy is a percentage
for i, v in enumerate(accuracies):
    axs[0].text(i, v + 0.5, f"{v:.2f}%", ha='center', va='bottom')

# Plotting weights
axs[1].bar(model_names, weights, color=['blue', 'green', 'red'])
axs[1].set_title('Model Weights in Ensemble')
axs[1].set_ylabel('Weight')
for i, v in enumerate(weights):
    axs[1].text(i, v + 0.02, f"{v:.2f}", ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Create an ensemble model
ensemble_model = EnsembleModel(loaded_mobile_net_v2_model, loaded_inceptionv3_model, resnet_model, weights).to(device)

# Fine-tune strategy
# First freeze the parameters of all models
for model in [loaded_mobile_net_v2_model, loaded_inceptionv3_model, resnet_model]:
    for param in model.parameters():
        param.requires_grad = False

# Selectively thaw certain layers for fine-tuning
# For example, only the last layer of MobileNetV2 is fine-tuned
for param in loaded_mobile_net_v2_model.mobilenetv2.classifier.parameters():
    param.requires_grad = True

# for InceptionV3Fine-tune the parameters of the secondary and primary classifiers
for param in loaded_inceptionv3_model.inceptionv3.AuxLogits.fc.parameters():
    param.requires_grad = True
for param in loaded_inceptionv3_model.inceptionv3.fc.parameters():
    param.requires_grad = True

# For ResNet, fine-tune the final convolutional layer
for param in resnet_model.layer4.parameters():
    param.requires_grad = True

"""# Training"""

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(ensemble_model.parameters(), lr=0.0001)

# Define an early stop class
class EarlyStopping:
    def __init__(self, patience=7, delta=0):
        self.patience = patience
        self.delta = delta
        self.best_loss = None
        self.early_stop = False
        self.counter = 0

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss + self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

# instantiate
early_stopping = EarlyStopping(patience=5, delta=0.01)

# Training and testing 0.001)
EPOCHS = 50
train_losses, test_losses = [], []
train_accuracies, test_accuracies = [], []

for epoch in range(EPOCHS):
    ensemble_model.train()
    epoch_train_loss = 0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = ensemble_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        epoch_train_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    train_accuracy = 100 * correct_train / total_train
    epoch_train_loss /= total_train

    # Testing phase
    ensemble_model.eval()
    epoch_test_loss = 0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = ensemble_model(images)
            loss = criterion(outputs, labels)

            epoch_test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

    test_accuracy = 100 * correct_test / total_test
    epoch_test_loss /= total_test

    train_losses.append(epoch_train_loss)
    test_losses.append(epoch_test_loss)
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    # early stopping check-ups
    early_stopping(epoch_test_loss)
    if early_stopping.early_stop:
        print("Early stopping")
        break

# Plot losses and accuracy
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Training and testing (0.01)
EPOCHS = 50
train_losses, test_losses = [], []
train_accuracies, test_accuracies = [], []

for epoch in range(EPOCHS):
    ensemble_model.train()
    epoch_train_loss = 0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = ensemble_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        epoch_train_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    train_accuracy = 100 * correct_train / total_train
    epoch_train_loss /= total_train

    ensemble_model.eval()
    epoch_test_loss = 0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = ensemble_model(images)
            loss = criterion(outputs, labels)

            epoch_test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

    test_accuracy = 100 * correct_test / total_test
    epoch_test_loss /= total_test

    train_losses.append(epoch_train_loss)
    test_losses.append(epoch_test_loss)
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    early_stopping(epoch_test_loss)
    if early_stopping.early_stop:
        print("Early stopping")
        break

# Plot losses and accuracy
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Training and testing (0.0005)
EPOCHS = 50
train_losses, test_losses = [], []
train_accuracies, test_accuracies = [], []

for epoch in range(EPOCHS):
    ensemble_model.train()
    epoch_train_loss = 0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = ensemble_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        epoch_train_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    train_accuracy = 100 * correct_train / total_train
    epoch_train_loss /= total_train

    ensemble_model.eval()
    epoch_test_loss = 0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = ensemble_model(images)
            loss = criterion(outputs, labels)

            epoch_test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

    test_accuracy = 100 * correct_test / total_test
    epoch_test_loss /= total_test

    train_losses.append(epoch_train_loss)
    test_losses.append(epoch_test_loss)
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    early_stopping(epoch_test_loss)
    if early_stopping.early_stop:
        print("Early stopping")
        break

# Plot losses and accuracy
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Plot losses and accuracy
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(ensemble_model.parameters(), lr=0.01)
# Learning Rate Scheduler
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

# early stopping class
class EarlyStopping:
    def __init__(self, patience=7, delta=0):
        self.patience = patience
        self.delta = delta
        self.best_loss = None
        self.early_stop = False
        self.counter = 0

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss + self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

early_stopping = EarlyStopping(patience=4, delta=0.01)

# Training and testing (Learning Rate Scheduler)
EPOCHS = 50
train_losses, test_losses = [], []
train_accuracies, test_accuracies = [], []

best_test_accuracy = 0.0
best_epoch = 0
best_model_state = None

for epoch in range(EPOCHS):
    ensemble_model.train()
    epoch_train_loss = 0
    correct_train = 0
    total_train = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = ensemble_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        epoch_train_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()

    train_accuracy = 100 * correct_train / total_train
    epoch_train_loss /= total_train

    ensemble_model.eval()
    epoch_test_loss = 0
    correct_test = 0
    total_test = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = ensemble_model(images)
            loss = criterion(outputs, labels)

            epoch_test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

    test_accuracy = 100 * correct_test / total_test
    epoch_test_loss /= total_test

    train_losses.append(epoch_train_loss)
    test_losses.append(epoch_test_loss)
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)

    print(f"Epoch [{epoch + 1}/{EPOCHS}], "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Test Loss: {epoch_test_loss:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Test Accuracy: {test_accuracy:.2f}%")

    # Update the best model logic
    if test_accuracy > best_test_accuracy:
        best_test_accuracy = test_accuracy  # Update the best validation/test accuracy
        best_epoch = epoch + 1  # Update the best epoch
        best_model_state = ensemble_model.state_dict()  # Save the model's state_dict

    # Step the scheduler
    scheduler.step()

    # Early stopping check
    early_stopping(epoch_test_loss)
    if early_stopping.early_stop:
        print("Early stopping")
        break

# Print the best test accuracy after the training loop has completed
print(f"Best Test Accuracy: {best_test_accuracy:.2f}% at Epoch {best_epoch}")

# Plot losses and accuracy
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Plot losses and accuracy
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

torch.save(ensemble_model, '/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/best_ensemble_model.pth')

"""# evaluation"""

model = torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/best_ensemble_model.pth')
model = model.eval().to(device)

print(model)

import torch
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np

model.eval()
predictions = []
true_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        outputs = model(images)
        _, predicted_classes = torch.max(outputs, 1)
        predictions.extend(predicted_classes.cpu().numpy())
        true_labels.extend(labels.numpy())

# Displays the image and the prediction result
def show_images_with_predictions(dataloader, predictions, true_labels, class_names, num_images=10):
    plt.figure(figsize=(20, 10))
    images_shown = 0
    for images, labels in dataloader:
        for i in range(len(images)):
            if images_shown >= num_images:
                break
            ax = plt.subplot(num_images // 5, 5, images_shown + 1)
            ax.axis('off')
            correct = '' if predictions[images_shown] == true_labels[images_shown] else ''
            ax.set_title(f'Pred: {class_names[predictions[images_shown]]}\nTrue: {class_names[true_labels[images_shown]]} {correct}', color=("green" if correct == "" else "red"))
            image = images[i].numpy().transpose((1, 2, 0))
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            image = std * image + mean
            image = np.clip(image, 0, 1)
            plt.imshow(image)
            images_shown += 1
    plt.tight_layout()
    plt.show()

show_images_with_predictions(test_loader, predictions, true_labels, class_names)

import torch
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import torch.nn.functional as F

def preprocess_image(image_path):
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    image = Image.open(image_path)
    image = transform(image).unsqueeze(0)
    return image

def predict_image(model, processed_image, device):
    processed_image = processed_image.to(device)
    with torch.no_grad():
        logits = model(processed_image)
        probabilities = F.softmax(logits, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1)
    return probabilities, predicted_class.item()


image_path = "/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split/test/cheesecake/1021942.jpg"
processed_image = preprocess_image(image_path)
probabilities, predicted_class = predict_image(model, processed_image, device)
print("Class probabilities:")
for i, prob in enumerate(probabilities[0]):  # Access the first batch of probabilities
    print(f"{class_names[i]}: {prob.item()*100:.2f}%")

"""* confusion matrix"""

import itertools
import matplotlib.pyplot as plt
import numpy as np
import torch
from sklearn.metrics import confusion_matrix
from torchvision.models.inception import InceptionOutputs

def plot_confusion_matrix(model, test_loader, class_names):
    ensemble_model.eval()  # Set the model to evaluation mode
    device = next(ensemble_model.parameters()).device  # Get the device the model is on

    all_preds = []
    all_labels = []

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = ensemble_model(images)  # Perform forward pass to get predictions

            # Special handling for models that return multiple outputs like InceptionV3
            if isinstance(outputs, InceptionOutputs):
                outputs = outputs.logits  # Use only the main output if it's InceptionOutputs

            _, preds = torch.max(outputs, 1)  # Get predicted classes
            all_preds.extend(preds.cpu().numpy())  # Append predictions
            all_labels.extend(labels.cpu().numpy())  # Append labels

    cm = confusion_matrix(all_labels, all_preds)  # Calculate confusion matrix

    plt.figure(figsize=(10, 8))
    plt.imshow(cm, interpolation='nearest', cmap='Reds')
    plt.colorbar()

    ticks = np.arange(len(class_names))
    plt.xticks(ticks, class_names, rotation=90)
    plt.yticks(ticks, class_names)

    plt.title('Confusion Matrix')

    threshold = cm.max() / 2  # Update threshold for better text visibility
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, "{:,}".format(cm[i, j]),
                 horizontalalignment='center',
                 color='white' if cm[i, j] > threshold else 'black')

    plt.tight_layout()
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')

plot_confusion_matrix(ensemble_model, test_loader, class_names)
plt.show()

"""

*   ROC Curve for Multi-Class Classification

"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import torch
num_classes = 5;

def generate_roc_curve(model, test_loader, class_names):
    num_classes = len(class_names)
    ensemble_model.eval()  # Set the model to evaluation mode
    device = next(ensemble_model.parameters()).device  # Get the device the model is on

    all_preds = []
    all_labels = []

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = ensemble_model(images)  # Perform forward pass to get predictions
            all_preds.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())  # Append predictions
            all_labels.extend(labels.cpu().numpy())  # Append labels

    y_pred = np.array(all_preds)
    y_true = np.array(all_labels)

    # Convert labels to one-hot encoding
    y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))

    # Compute ROC curve and ROC area for each class
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve(y_true_one_hot[:, i], y_pred[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Plot ROC curves
    plt.figure(figsize=(8, 6))
    for i in range(num_classes):
        plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')

    plt.plot([0, 1], [0, 1], 'k--', linewidth=2)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve for Multi-Class Classification')
    plt.legend(loc='lower right')
    plt.show()

generate_roc_curve(ensemble_model, test_loader, class_names)

"""
*  Precision-Recall Curve for Multi-Class Classification

"""

def generate_precision_recall_curve_train(model, train_loader, class_names):
    num_classes = len(class_names)
    ensemble_model.eval()  # Set the model to evaluation mode
    device = next(ensemble_model.parameters()).device  # Get the device the model is on

    all_preds = []
    all_labels = []

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in train_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = ensemble_model(images)  # Perform forward pass to get predictions
            all_preds.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())  # Append predictions
            all_labels.extend(labels.cpu().numpy())  # Append labels

    y_pred = np.array(all_preds)
    y_true = np.array(all_labels)

    # Convert labels to one-hot encoding
    y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))

    # Compute precision and recall for each class
    precision = dict()
    recall = dict()
    pr_auc = dict()

    for i in range(num_classes):
        precision[i], recall[i], _ = precision_recall_curve(y_true_one_hot[:, i], y_pred[:, i])
        pr_auc[i] = auc(recall[i], precision[i])

    # Plot Precision-Recall curves
    plt.figure(figsize=(8, 6))
    for i in range(num_classes):
        plt.plot(recall[i], precision[i], label=f'{class_names[i]} (AUC = {pr_auc[i]:.2f})')

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve for Multi-Class Classification (Training Data)')
    plt.legend(loc='lower right')
    plt.show()

generate_precision_recall_curve_train(ensemble_model, train_loader, class_names)

""""""

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(true_labels, predictions)
print(f"Accuracy: {accuracy:.2f}")

from sklearn.metrics import f1_score, precision_score, recall_score

precision = precision_score(true_labels, predictions, average='macro')
recall = recall_score(true_labels, predictions, average='macro')
f1 = f1_score(true_labels, predictions, average='macro')

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

import matplotlib.pyplot as plt
import numpy as np

# Assuming you have multiple classes in your classification task
class_labels = range(n_classes)

class_precision = precision_score(true_labels, predictions, average=None)
class_recall = recall_score(true_labels, predictions, average=None)
class_f1 = f1_score(true_labels, predictions, average=None)

# Plotting
x = np.arange(len(class_labels))  # the label locations
width = 0.2  # the width of the bars

fig, ax = plt.subplots(figsize=(12, 6))
rects1 = ax.bar(x - width, class_precision, width, label='Precision')
rects2 = ax.bar(x, class_recall, width, label='Recall')
rects3 = ax.bar(x + width, class_f1, width, label='F1 Score')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_xlabel('Classes')
ax.set_ylabel('Scores')
ax.set_title('Scores by class')
ax.set_xticks(x)
ax.set_xticklabels(class_names)
ax.legend()

plt.show()

"""* value of Acc     Pre     Sen     Spe      F1     mAP"""

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, confusion_matrix
from sklearn.preprocessing import label_binarize
import torch
from tabulate import tabulate

def generate_metrics(model, test_loader, class_names):
    num_classes = len(class_names)
    model.eval()  # Set the model to evaluation mode
    device = next(model.parameters()).device  # Get the device the model is on

    all_preds = []
    all_labels = []

    with torch.no_grad():  # Disable gradient calculation
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)  # Perform forward pass to get predictions
            all_preds.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())  # Append predictions
            all_labels.extend(labels.cpu().numpy())  # Append labels

    y_pred = np.array(all_preds)
    y_true = np.array(all_labels)

    # Convert labels to one-hot encoding
    y_true_one_hot = label_binarize(y_true, classes=np.arange(num_classes))

    # Initialize metric containers
    metrics = []

    # Compute evaluation metrics for each class
    for i in range(num_classes):
        acc = accuracy_score(y_true_one_hot[:, i], y_pred[:, i] > 0.5)
        pre = precision_score(y_true_one_hot[:, i], y_pred[:, i] > 0.5)
        rec = recall_score(y_true_one_hot[:, i], y_pred[:, i] > 0.5)
        tn, fp, fn, tp = confusion_matrix(y_true_one_hot[:, i], y_pred[:, i] > 0.5).ravel()
        spe = tn / (tn + fp)
        f1 = f1_score(y_true_one_hot[:, i], y_pred[:, i] > 0.5)
        ap = average_precision_score(y_true_one_hot[:, i], y_pred[:, i])

        # Append metrics to the list
        metrics.append([class_names[i], acc, pre, rec, spe, f1, ap])

    # Create table headers
    headers = ['Class', 'Acc', 'Pre', 'Sen', 'Spe', 'F1', 'mAP']

    # Print the table
    print(tabulate(metrics, headers=headers, floatfmt=".4f"))

# Assuming you have defined `model` and `test_loader` previously
# Also assuming `class_names` is a list of class names
# Usage: pass your PyTorch model, test_loader, and class names to generate metrics
generate_metrics(model, test_loader, class_names)

"""# Interpretability"""

!pip install grad-cam torchcam

!git clone https://github.com/jacobgil/pytorch-grad-cam.git

import pytorch_grad_cam

"""*  Grad-CAM"""

# Commented out IPython magic to ensure Python compatibility.
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from torchvision.models import resnet50
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
# %matplotlib inline
import torch

from torchvision import transforms

test_transform = transforms.Compose([transforms.Resize(512),
                    transforms.ToTensor(),
                    transforms.Normalize(
                        mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
                  ])

img_path = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split/test/cheesecake/1021942.jpg'

img_pil = Image.open(img_path)

input_tensor = test_transform(img_pil).unsqueeze(0).to(device)

input_tensor.shape

targets = [ClassifierOutputTarget(1)]

model

model.modelC.layer4[1]

model.modelC.resnet.features[18]

# Grad-CAM
from pytorch_grad_cam import GradCAM
target_layers = [model.modelC.layer4[1]]
cam = GradCAM(model=model, target_layers=target_layers)

cam_map = cam(input_tensor=input_tensor, targets=targets)[0]

cam_map.shape

plt.imshow(cam_map)
plt.show()

import torchcam
from torchcam.utils import overlay_mask

result = overlay_mask(img_pil, Image.fromarray(cam_map), alpha=0.5)
result

"""* Guided Backpropagation"""

from pytorch_grad_cam import GuidedBackpropReLUModel
from pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image


gb_model = GuidedBackpropReLUModel(model=model, device=device)

gb_origin = gb_model(input_tensor, target_category=None)
gb_show = deprocess_image(gb_origin)

gb_show.shape

plt.imshow(gb_show)
plt.title('Guided Backpropagation')
plt.show()

cam_mask = cv2.merge([cam_map, cam_map, cam_map])
cam_mask.shape

guided_gradcam = deprocess_image(cam_mask * gb_origin)
guided_gradcam.shape

plt.imshow(guided_gradcam)
plt.title('Guided Grad-CAM')
plt.show()

"""* SHAP"""

!pip install numpy pandas matplotlib requests tqdm opencv-python pillow shap tensorflow keras -i https://pypi.tuna.tsinghua.edu.cn/simple

import json
import numpy as np
from PIL import Image
import torch
import torch.nn as nn
import torchvision
from torchvision import transforms
import shap

img_path = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split/train/ice_cream/1004744.jpg'
img_pil = Image.open(img_path)
X = torch.Tensor(np.array(img_pil)).unsqueeze(0)
X.shape

img_path = '/content/drive/MyDrive/Colab Notebooks/Projects/datasets/Food Classification dataset_split/train/apple_pie/1272778.jpg'
img_pil = Image.open(img_path)
X = torch.Tensor(np.array(img_pil)).unsqueeze(0)
X.shape

mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

def nhwc_to_nchw(x: torch.Tensor) -> torch.Tensor:
    if x.dim() == 4:
        x = x if x.shape[1] == 3 else x.permute(0, 3, 1, 2)
    elif x.dim() == 3:
        x = x if x.shape[0] == 3 else x.permute(2, 0, 1)
    return x

def nchw_to_nhwc(x: torch.Tensor) -> torch.Tensor:
    if x.dim() == 4:
        x = x if x.shape[3] == 3 else x.permute(0, 2, 3, 1)
    elif x.dim() == 3:
        x = x if x.shape[2] == 3 else x.permute(1, 2, 0)
    return x


transform= [
    transforms.Lambda(nhwc_to_nchw),
    transforms.Resize(224),
    transforms.Lambda(lambda x: x*(1/255)),
    transforms.Normalize(mean=mean, std=std),
    transforms.Lambda(nchw_to_nhwc),
]

inv_transform= [
    transforms.Lambda(nhwc_to_nchw),
    transforms.Normalize(
        mean = (-1 * np.array(mean) / np.array(std)).tolist(),
        std = (1 / np.array(std)).tolist()
    ),
    transforms.Lambda(nchw_to_nhwc),
]

transform = torchvision.transforms.Compose(transform)
inv_transform = torchvision.transforms.Compose(inv_transform)

def predict(img: np.ndarray) -> torch.Tensor:
    img = nhwc_to_nchw(torch.Tensor(img)).to(device)
    output = model(img)
    return output
def predict(img):
    img = nhwc_to_nchw(torch.Tensor(img)).to(device)
    output = model(img)
    return output

Xtr = transform(X)
out = predict(Xtr[0:1])
out.shape

classes = torch.argmax(out, axis=1).detach().cpu().numpy()
print(f'Classes: {classes}: {np.array(class_names)[classes]}')

input_img = Xtr[0].unsqueeze(0)
input_img.shape

batch_size = 50

n_evals = 5000

masker_blur = shap.maskers.Image("blur(64, 64)", Xtr[0].shape)

explainer = shap.Explainer(predict, masker_blur, output_names=class_names)

shap_values = explainer(input_img, max_evals=n_evals, batch_size=batch_size, outputs=[0,3])

shap_values.data = inv_transform(shap_values.data).cpu().numpy()[0] # original image
shap_values.values = [val for val in np.moveaxis(shap_values.values[0],-1, 0)] # Shap value heat map

shap_values.values[0].shape

shap_values.values[0].shape

shap.image_plot(shap_values=shap_values.values,
                pixel_values=shap_values.data,
                labels=shap_values.output_names)

"""* Lime"""

!pip install lime scikit-learn numpy pandas matplotlib pillow

import matplotlib.pyplot as plt
from PIL import Image
import torch.nn as nn
import numpy as np
import os, json

import torch
from torchvision import models, transforms
from torch.autograd import Variable
import torch.nn.functional as F

len(idx_to_labels)

trans_norm = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                  std=[0.229, 0.224, 0.225])

trans_A = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    trans_norm
    ])

trans_B = transforms.Compose([
        transforms.ToTensor(),
        trans_norm
    ])

trans_C = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224)
])

input_tensor = trans_A(img_pil).unsqueeze(0).to(device)
pred_logits = model(input_tensor)
pred_softmax = F.softmax(pred_logits, dim=1)
top_n = pred_softmax.topk(5)

top_n

def batch_predict(images):
    batch = torch.stack(tuple(trans_B(i) for i in images), dim=0)
    batch = batch.to(device)

    logits = model(batch)
    probs = F.softmax(logits, dim=1)
    return probs.detach().cpu().numpy()

test_pred = batch_predict([trans_C(img_pil)])
test_pred.squeeze().argmax()

from lime import lime_image

explainer = lime_image.LimeImageExplainer()
explanation = explainer.explain_instance(np.array(trans_C(img_pil)),
                                         batch_predict,
                                         top_labels=len(idx_to_labels),
                                         hide_color=0,
                                         num_samples=3000)

explanation.top_labels[0]

from skimage.segmentation import mark_boundaries
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=20, hide_rest=False)
img_boundry = mark_boundaries(temp/255.0, mask)
plt.imshow(img_boundry)
plt.show()

temp, mask = explanation.get_image_and_mask(3, positive_only=False, num_features=20, hide_rest=False)
img_boundry = mark_boundaries(temp/255.0, mask)
plt.imshow(img_boundry)
plt.show()

"""# ONNX"""

!pip install onnx -i https://pypi.tuna.tsinghua.edu.cn/simple

!pip install onnxruntime -i https://pypi.tuna.tsinghua.edu.cn/simple

!pip install numpy pandas matplotlib tqdm opencv-python pillow -i https://pypi.tuna.tsinghua.edu.cn/simple

import torch
print('PyTorch Version', torch.__version__)

import onnx
print('ONNX Version', onnx.__version__)

import onnxruntime as ort
print('ONNX Runtime Version', ort.__version__)

import torch
from torchvision import models

#  GPU  GPU CPU
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print('device', device)

model = torch.load('/content/drive/MyDrive/Colab Notebooks/Projects/checkpoint/best_ensemble_model.pth')
model = model.eval().to(device)

print(model)

x = torch.randn(1, 3, 256, 256).to(device)

output = model(x)

x

output.shape

x = torch.randn(1, 3, 256, 256).to(device)

with torch.no_grad():
    torch.onnx.export(
        model,
        x,
        'ensemble_model.onnx',
        opset_version=11,
        input_names=['input'],
        output_names=['output']
    )

import onnx

onnx_model = onnx.load('/content/ensemble_model.onnx')

onnx.checker.check_model(onnx_model)

print('No error, onnx model loaded successfully')

print(onnx.helper.printable_graph(onnx_model.graph))

target_directory = '/content/drive/MyDrive/Colab Notebooks/Projects/ONNX'
os.makedirs(target_directory, exist_ok=True)

source_path = '/content/ensemble_model.onnx'
target_path = f'{target_directory}/ensemble_model.onnx'

!mv "{source_path}" "{target_path}"

x = torch.randn(1, 3, 256, 256).to(device)

with torch.no_grad():
    torch.onnx.export(
        loaded_inceptionv3_model,
        x,
        'inceptionv3_model.onnx',
        opset_version=11,
        input_names=['input'],
        output_names=['output']
    )

import onnx

onnx_model = onnx.load('/content/inceptionv3_model.onnx')

onnx.checker.check_model(onnx_model)

print('No error, onnx model loaded successfully')

print(onnx.helper.printable_graph(onnx_model.graph))